{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_raw = pd.read_csv(\"../data/AutoPhrase_single-word.txt\", delimiter=\"\\t\", header=None)\n",
    "single_raw.columns = ['score', 'entity']\n",
    "multi_raw = pd.read_csv(\"../data/AutoPhrase_multi-words.txt\", delimiter=\"\\t\", header=None)\n",
    "multi_raw.columns = ['score', 'entity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_high = single_raw[single_raw.score >= 0.9].entity.tolist()\n",
    "multi_high = multi_raw[multi_raw.score >= 0.5].entity.tolist()\n",
    "print(len(single_high),len(multi_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list = [e for e in list(set(single_high + multi_high)) if e is not np.nan]\n",
    "print(len(entity_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2id = {}\n",
    "eid = 0\n",
    "for e in entity_list:\n",
    "    entity2id.update({e:eid})\n",
    "    eid += 1\n",
    "id2entity = dict([(value, key) for key, value in entity2id.items()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/entitylist.txt', \"w+\") as f:\n",
    "    f.write('\\n'.join(entity_list))\n",
    "f.close()\n",
    "with open('../data/entity2id.txt', \"w+\") as f:\n",
    "    f.write(json.dumps(entity2id))\n",
    "f.close()\n",
    "with open('../data/id2entity.txt', \"w+\") as f:\n",
    "    f.write(json.dumps(id2entity))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/entity2id.txt', 'r') as f:\n",
    "    raw_entity2id = f.read()\n",
    "f.close()\n",
    "\n",
    "entity2id = json.loads(raw_entity2id)\n",
    "\n",
    "with open('../data/id2entity.txt', 'r') as f:\n",
    "    raw_id2entity = f.read()\n",
    "f.close()\n",
    "\n",
    "id2entity = json.loads(raw_id2entity)\n",
    "\n",
    "with open('../data/entitylist.txt', 'r') as f:\n",
    "    raw_list = f.read()\n",
    "f.close()\n",
    "\n",
    "entityset = set(raw_list.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MWETokenizer(separator=' ')\n",
    "\n",
    "for e in entityset:\n",
    "    tokenizer.add_mwe(e.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tokenized = tokenizer.tokenize(\"the pagani zonda r is a track day car developed and manufactured by italian sports car manufacturer pagani.\".split())\n",
    "tokenized_set = set(raw_tokenized)\n",
    "mentioned_entity = tokenized_set.intersection(entityset)\n",
    "mentioned2id = [entity2id[e] for e in mentioned_entity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_json = {}\n",
    "with open('../data/SENTENCE_ENTITY_AA', 'r') as f:\n",
    "    for line in f:\n",
    "        sent_json.update(json.loads(line))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
